"""
×× ×•×¢ ×”×ª×××ª ××•×¢××“×™× ×œ××©×¨×•×ª
××–×”×” ××•×¢××“×™× ×¤×•×˜× ×¦×™××œ×™×™× ×•××ª××™× ××•×ª× ×œ××©×¨×•×ª ×¤×ª×•×—×•×ª
Production Ready - ×¢× ×œ×•×’×™×§×” ×—×›××” ×•×–×™×”×•×™ ×”×§×©×¨
"""

import re
from typing import Dict, List, Tuple, Optional
from datetime import datetime, timedelta
import config


def analyze_with_llm(post_text: str) -> Optional[Dict]:
    """
    × ×™×ª×•×— ×¤×•×¡×˜ ×‘×××¦×¢×•×ª LLM ×œ×“×™×•×§ ××§×¡×™××œ×™

    Args:
        post_text: ×˜×§×¡×˜ ×”×¤×•×¡×˜ ×œ× ×™×ª×•×—

    Returns:
        dict ×¢× ×ª×•×¦××•×ª ×”× ×™×ª×•×— ××• None ×× ×œ× ×–××™×Ÿ

    TODO: ×œ×”×•×¡×™×£ ×§×¨×™××ª API ×œ-OpenAI/Gemini ×‘×¢×ª×™×“
    ×›×“×™ ×œ×§×‘×œ × ×™×ª×•×— ××“×•×™×§ ×™×•×ª×¨ ×©×œ:
    - ×”×× ×–×” ××•×¢××“ ××• ××¢×¡×™×§
    - ××™×–×” ×¡×•×’ ×¢×‘×•×“×” ××—×¤×©×™×
    - ×¨××ª × ×™×¡×™×•×Ÿ
    - ××™×§×•× ××•×¢×“×£

    Example implementation:
        import openai
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{
                "role": "system",
                "content": "Analyze if this Facebook post is from a job seeker..."
            }, {
                "role": "user",
                "content": post_text
            }]
        )
        return parse_llm_response(response)
    """
    # Placeholder - ×™×•×—×œ×£ ×‘×§×¨×™××ª API ×××™×ª×™×ª ×‘×¢×ª×™×“
    return None


def analyze_text_semantic(text: str, api_key: str = None) -> Optional[Dict]:
    """
    Semantic text analysis using OpenAI API for recruitment trend analysis.

    Args:
        text: The text to analyze
        api_key: OpenAI API key (optional, can use env var)

    Returns:
        dict with analysis results:
            - text_quality: float (0-1)
            - category: str (e.g., 'job_seeker', 'employer', 'other')
            - confidence: float (0-1)
            - keywords: List[str]
        Returns None if API is not configured.

    TODO: Implement actual OpenAI API call
    Example:
        from openai import OpenAI
        client = OpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Analyze text quality and classify..."},
                {"role": "user", "content": text}
            ],
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
    """
    # Placeholder - to be implemented with actual API integration
    return None


def is_employer_context(text: str, keyword: str) -> bool:
    """
    ×‘×“×™×§×” ×× ××™×œ×ª ××¤×ª×— ××•×¤×™×¢×” ×‘×”×§×©×¨ ×©×œ ××¢×¡×™×§

    Examples:
        "×× ×—× ×• ××©×œ××™× ××©×›×•×¨×ª ×’×‘×•×”×”" -> True (××¢×¡×™×§)
        "×× ×™ ××—×¤×© ××©×›×•×¨×ª ×’×‘×•×”×”" -> False (××•×¢××“)
    """
    # ×”×§×©×¨×™× ×©××¢×™×“×™× ×¢×œ ××¢×¡×™×§
    employer_prefixes = [
        "×× ×—× ×• ××¦×™×¢×™×", "×× ×• ××¦×™×¢×™×", "×”×—×‘×¨×” ××¦×™×¢×”",
        "× ×•×ª× ×™×", "××¦×™×¢×™×", "×›×•×œ×œ", "×¢× ××¤×©×¨×•×ª",
        "×”××©×¨×” ×›×•×œ×œ×ª", "×”×ª×¤×§×™×“ ×›×•×œ×œ",
        "×× ×—× ×• ××©×œ××™×", "××©×œ××™×", "×©×›×¨ ×©×œ",
    ]

    text_lower = text.lower()
    keyword_pos = text_lower.find(keyword.lower())

    if keyword_pos == -1:
        return False

    # ×‘×“×•×§ 50 ×ª×•×•×™× ×œ×¤× ×™ ×”××™×œ×”
    context_before = text_lower[max(0, keyword_pos - 50):keyword_pos]

    for prefix in employer_prefixes:
        if prefix in context_before:
            return True

    return False


class CandidateMatcher:
    """××–×”×” ×•××ª××™× ××•×¢××“×™× ×œ××©×¨×•×ª"""
    
    def __init__(self):
        self.positive_keywords = config.CANDIDATE_KEYWORDS['positive']
        self.negative_keywords = config.CANDIDATE_KEYWORDS['negative']
        self.open_positions = config.OPEN_POSITIONS
    
    def is_candidate_post(self, post_text: str) -> Tuple[bool, float, List[str]]:
        """
        ×‘×“×™×§×” ×”×× ×¤×•×¡×˜ ×”×•× ×©×œ ××•×¢××“ ××—×¤×© ×¢×‘×•×“×”

        Returns:
            tuple: (×”×× ××•×¢××“, ×¦×™×•×Ÿ, ××™×œ×•×ª ××¤×ª×— ×©× ××¦××•)
        """
        if not post_text:
            return False, 0.0, []

        # × ×¡×” ×œ× ×ª×— ×¢× LLM ×× ×–××™×Ÿ (×œ×“×™×•×§ ××§×¡×™××œ×™)
        llm_result = analyze_with_llm(post_text)
        if llm_result is not None:
            return (
                llm_result.get('is_candidate', False),
                llm_result.get('score', 0.0),
                llm_result.get('keywords', [])
            )

        # ×œ× ××©× ×™× ×œ-lower ×¢×‘×•×¨ ×¢×‘×¨×™×ª - ×‘×•×“×§×™× ××ª ×”×˜×§×¡×˜ ×”××§×•×¨×™
        post_text_check = post_text.lower()  # ×œ×× ×’×œ×™×ª

        # ×‘×“×™×§×ª ××™×œ×•×ª ××¤×ª×— ×©×œ×™×œ×™×•×ª (××¢×¡×™×§ ××—×¤×© ×¢×•×‘×“×™×)
        # ×—×›× ×™×•×ª×¨: ×‘×•×“×§ ×”×§×©×¨ ×•×œ× ×¨×§ ×§×™×•× ×”××™×œ×”
        for negative_keyword in self.negative_keywords:
            if negative_keyword in post_text_check or negative_keyword in post_text:
                # ××™×œ×™× ×©×ª××™×“ ×¤×•×¡×œ×•×ª (×œ× ×ª×œ×•×™×•×ª ×”×§×©×¨)
                always_disqualify = [
                    "×“×¨×•×©×™×", "×“×¨×•×©/×”", "×“×¨×•×©×”", "××’×™×™×¡×™×", "××’×™×™×¡×ª",
                    "×—×‘×¨×ª× ×• ××—×¤×©×ª", "×”×—×‘×¨×” ××—×¤×©×ª", "×× ×—× ×• ××—×¤×©×™×",
                    "hiring", "we are looking for", "recruiting"
                ]
                if any(word in post_text_check or word in post_text for word in always_disqualify):
                    return False, 0.0, []

        # ×¡×™×× ×™× ×©×œ ××•×“×¢×ª ×“×¨×•×©×™× ×©×ª×œ×•×™×™× ×‘×”×§×©×¨
        context_dependent_patterns = [
            "××©×›×•×¨×ª", "×©×›×¨ ×’×‘×•×”", "×‘×•× ×•×¡×™×", "×ª× ××™× ××¢×•×œ×™×", "×ª× ××™× ×˜×•×‘×™×"
        ]

        # ×¡×™×× ×™× ×©×ª××™×“ ××¢×™×“×™× ×¢×œ ××¢×¡×™×§ (×œ× ×ª×œ×•×™×™× ×‘×”×§×©×¨)
        employer_only_patterns = [
            "ğŸ“",  # ×˜×œ×¤×•×Ÿ ×‘×¤×•×¡×˜ = ×›× ×¨××” ××•×“×¢×”
            "â˜",
            "×§×•\"×— ×œ",
            "×©×œ×—×• ×œ",
            "×¤× ×• ×œ",
            "×¦×¨×• ×§×©×¨",
            "× × ×œ×¤× ×•×ª",
            "×™×© ×œ×©×œ×•×—",
            "×œ×©×œ×™×—×ª",
            "× ×™×ª×Ÿ ×œ×¤× ×•×ª",
            "××¡×¤×¨ ×˜×œ×¤×•×Ÿ",
            "×œ×”×’×™×© ××•×¢××“×•×ª",
            "×œ×©×œ×•×— ×§×•×¨×•×ª ×—×™×™× ×œ",
            # ××’×™×™×¡×™×/×—×‘×¨×•×ª ××—×¤×©×•×ª ×¢×•×‘×“×™×
            "××—×¤×© ××™×©×”×•",
            "××—×¤×©×ª ××™×©×”×•",
            "××—×¤×©×™× ××ª",
            "××—×¤×©×ª ××ª ×”",
            "××—×¤×© ××•×ª×š",
            "××—×¤×©×ª ××•×ª×š",
            "×‘×•××• ×œ×¢×‘×•×“",
            "×‘×•× ×œ×¢×‘×•×“",
            "×”×¦×˜×¨×¤×• ×œ×¦×•×•×ª",
            "×”×¦×˜×¨×¤×• ××œ",
            "××™×–×",
            "×©×•×ª×¤×•×ª",
            "×©×•×ª×¤×™×",
            "×¢×•×‘×“×™×/×•×ª",
            "××•××—×™",
            "××•××—×™×•×ª",
        ]

        for pattern in employer_only_patterns:
            if pattern in post_text or pattern.lower() in post_text_check:
                return False, 0.0, []

        # ×‘×“×™×§×ª ×“×¤×•×¡×™× ×ª×œ×•×™×™ ×”×§×©×¨
        for pattern in context_dependent_patterns:
            if pattern in post_text or pattern.lower() in post_text_check:
                # ×× ×–×” ×‘×”×§×©×¨ ×©×œ ××¢×¡×™×§ - ×¤×¡×•×œ
                if is_employer_context(post_text, pattern):
                    return False, 0.0, []
                # ×× ×–×” ×‘×”×§×©×¨ ×©×œ ××•×¢××“ (××—×¤×© ××©×›×•×¨×ª ×’×‘×•×”×”) - ×–×” ×‘×¡×“×¨

        # ×‘×“×™×§×ª ××™×œ×•×ª ××¤×ª×— ×—×™×•×‘×™×•×ª (××•×¢××“ ××—×¤×© ×¢×‘×•×“×”)
        matched_keywords = []
        for positive_keyword in self.positive_keywords:
            if positive_keyword in post_text_check or positive_keyword in post_text:
                matched_keywords.append(positive_keyword)

        # ×‘×™×˜×•×™×™× × ×•×¡×¤×™× ×©××¢×™×“×™× ×¢×œ ××—×¤×© ×¢×‘×•×“×” (×œ× ××¢×¡×™×§)
        seeker_phrases = [
            ("×“×¨×•×©×” ×œ×™", "×“×¨×•×©×” ×œ×™"),
            ("×—×¦×™ ××©×¨×”", "×—×¦×™ ××©×¨×”"),
            ("×¢×‘×•×“×” ××”×‘×™×ª", "×¢×‘×•×“×” ××”×‘×™×ª"),
            ("×œ×œ× × ×™×¡×™×•×Ÿ", "×œ×œ× × ×™×¡×™×•×Ÿ"),
            ("×‘×œ×™ × ×™×¡×™×•×Ÿ", "×‘×œ×™ × ×™×¡×™×•×Ÿ"),
            ("××—×¤×© ×¢×‘×•×“×”", "××—×¤×© ×¢×‘×•×“×” (×‘×™×˜×•×™)"),
            ("××—×¤×©×ª ×¢×‘×•×“×”", "××—×¤×©×ª ×¢×‘×•×“×” (×‘×™×˜×•×™)"),
            ("××—×¤×© ××©×¨×”", "××—×¤×© ××©×¨×” (×‘×™×˜×•×™)"),
            ("××—×¤×©×ª ××©×¨×”", "××—×¤×©×ª ××©×¨×” (×‘×™×˜×•×™)"),
            ("××—×¤×©×ª ×”×–×“×× ×•×ª", "××—×¤×©×ª ×”×–×“×× ×•×ª"),
            ("××—×¤×© ×”×–×“×× ×•×ª", "××—×¤×© ×”×–×“×× ×•×ª"),
        ]
        for phrase, label in seeker_phrases:
            if phrase in post_text and label not in matched_keywords:
                matched_keywords.append(label)

        # ×—×™×©×•×‘ ×¦×™×•×Ÿ
        if len(matched_keywords) == 0:
            return False, 0.0, []

        # ×¦×™×•×Ÿ ×-0 ×¢×“ 10
        score = min(len(matched_keywords) * 2.5, 10.0)

        # ×‘×•× ×•×¡ ×× ×”×¤×•×¡×˜ ×§×¦×¨ (×¡×‘×™×¨ ×©×–×” ××—×¤×© ×¢×‘×•×“×” ×•×œ× ××©×”×• ××—×¨)
        if len(post_text) < 300:
            score += 1.5

        # ×‘×•× ×•×¡ ×× ×™×© ×”×ª×™×™×—×¡×•×ª ×œ××™×§×•×
        locations = ["×¤×ª×— ×ª×§×•×•×”", "×”×•×“ ×”×©×¨×•×Ÿ", "×›×¤×¨ ×¡×‘×", "×¨×¢× × ×”", "×”××¨×›×–", "×”×©×¨×•×Ÿ"]
        for location in locations:
            if location in post_text:
                score += 0.5

        # ×‘×•× ×•×¡ ×× ×”×¤×•×¡×˜ ×‘×’×•×£ ×¨××©×•×Ÿ (×× ×™ ××—×¤×©, ×× ×™ ×¦×¨×™×š)
        first_person_patterns = ["×× ×™ ××—×¤×©", "×× ×™ ×¦×¨×™×š", "×× ×™ ×¨×•×¦×”", "×× ×™ ××¢×•× ×™×™×Ÿ", "×× ×™ ×–××™×Ÿ",
                                 "×× ×™ ××—×¤×©×ª", "×× ×™ ××¢×•× ×™×™× ×ª", "×× ×™ ×–××™× ×”"]
        for pattern in first_person_patterns:
            if pattern in post_text:
                score += 2.0
                break

        # ×‘×•× ×•×¡ ×× ××¦×™×™× ×™× ×’×™×œ (×‘×Ÿ/×‘×ª XX) - ××—×¤×©×™ ×¢×‘×•×“×” ××¦×™×™× ×™× ×’×™×œ
        age_pattern = re.search(r'\b×‘×Ÿ\s+\d{2}\b|\b×‘×ª\s+\d{2}\b', post_text)
        if age_pattern:
            score += 1.5

        score = min(score, 10.0)  # ××§×¡×™××•× 10

        is_candidate = score >= 4.0  # ×¡×£ ××•×ª××

        return is_candidate, score, matched_keywords
    
    def match_to_job(self, post_text: str, _author_name: str = "") -> Optional[Dict]:
        """
        ×”×ª×××ª ××•×¢××“ ×œ××©×¨×” ××ª××™××”
        
        Returns:
            dict: ×¤×¨×˜×™ ×”××©×¨×” ×”××ª××™××” ×‘×™×•×ª×¨ ××• None ×× ××™×Ÿ ×”×ª×××”
        """
        post_text_lower = post_text.lower()
        best_match = None
        best_score = 0.0
        
        for job_key, job_info in self.open_positions.items():
            match_score = 0.0
            matched_requirements = []
            
            # ×”×ª×××” ×œ×¤×™ ××™×œ×•×ª ××¤×ª×— ×©×œ ×”××©×¨×”
            for keyword in job_info['keywords']:
                if keyword in post_text_lower:
                    match_score += 2.0
                    matched_requirements.append(keyword)
            
            # ×‘×“×™×§×ª ××™×§×•×
            for location in job_info['locations']:
                if location in post_text:
                    match_score += 1.5
                    break
            
            # ×× ×™×© ×”×ª×××” ×˜×•×‘×”, ×©××•×¨ ××•×ª×”
            if match_score > best_score:
                best_score = match_score
                best_match = {
                    "job_key": job_key,
                    "job_info": job_info,
                    "match_score": match_score,
                    "matched_keywords": matched_requirements
                }
        
        # ×”×—×–×¨×ª ×”××©×¨×” ×”×›×™ ×˜×•×‘×” ×× ×™×© ×¦×™×•×Ÿ ××¡×¤×™×§
        if best_match and best_match['match_score'] >= 1.5:
            return best_match
        
        # ×× ××™×Ÿ ×”×ª×××” ×¡×¤×¦×™×¤×™×ª, × ×—×–×™×¨ ××ª ×”××©×¨×” ×”×›×œ×œ×™×ª ×‘×™×•×ª×¨
        # (×¡×•×›×Ÿ ×‘×™×˜×•×— - ×”×›×™ ×›×œ×œ×™)
        default_job = self.open_positions.get("×¡×•×›×Ÿ ×‘×™×˜×•×—")
        if default_job:
            return {
                "job_key": "×¡×•×›×Ÿ ×‘×™×˜×•×—",
                "job_info": default_job,
                "match_score": 2.0,  # ×¦×™×•×Ÿ ×‘×¡×™×¡×™
                "matched_keywords": []
            }
        
        return None
    
    def extract_candidate_info(self, post_text: str, author_name: str = "") -> Dict:
        """
        ×—×™×œ×•×¥ ××™×“×¢ ×¢×œ ×”××•×¢××“ ××”×¤×•×¡×˜
        
        Returns:
            dict: ××™×“×¢ ×¢×œ ×”××•×¢××“
        """
        info = {
            "name": author_name,
            "has_phone": False,
            "has_experience": False,
            "locations_mentioned": [],
            "skills_mentioned": []
        }
        
        # ×—×™×¤×•×© ××¡×¤×¨ ×˜×œ×¤×•×Ÿ
        phone_pattern = r'0\d{1,2}[-\s]?\d{7}'
        if re.search(phone_pattern, post_text):
            info['has_phone'] = True
        
        # ×—×™×¤×•×© × ×™×¡×™×•×Ÿ
        experience_keywords = ["× ×™×¡×™×•×Ÿ", "×¢×‘×“×ª×™", "×”×ª× ×¡×•×ª", "×©× ×™×", "×©× ×•×ª"]
        for keyword in experience_keywords:
            if keyword in post_text.lower():
                info['has_experience'] = True
                break
        
        # ××™×§×•××™×
        locations = ["×¤×ª×— ×ª×§×•×•×”", "×”×•×“ ×”×©×¨×•×Ÿ", "×›×¤×¨ ×¡×‘×", "×¨×¢× × ×”", "×”××¨×›×–", "×”×©×¨×•×Ÿ", "×ª×œ ××‘×™×‘"]
        for location in locations:
            if location in post_text:
                info['locations_mentioned'].append(location)
        
        # ××™×•×× ×•×™×•×ª ×¨×œ×•×•× ×˜×™×•×ª
        skills = ["××›×™×¨×•×ª", "×©×™×¨×•×ª", "×‘×™×˜×•×—", "×œ×§×•×—×•×ª", "××—×©×‘", "××©×¨×“", "×˜×œ×¤×•×Ÿ"]
        for skill in skills:
            if skill in post_text.lower():
                info['skills_mentioned'].append(skill)
        
        return info
    
    def should_respond(self, post_data: Dict) -> Tuple[bool, str]:
        """
        ×”×—×œ×˜×” ×× ×œ×¢× ×•×ª ×œ×¤×•×¡×˜
        
        Returns:
            tuple: (×”×× ×œ×¢× ×•×ª, ×¡×™×‘×”)
        """
        # ×‘×“×™×§×ª ×’×™×œ ×”×¤×•×¡×˜
        posted_at = post_data.get('posted_at')
        if posted_at:
            try:
                posted_date = datetime.fromisoformat(posted_at)
                max_age = timedelta(days=config.AUTOMATION_SETTINGS['max_post_age_days'])
                
                if datetime.now() - posted_date > max_age:
                    return False, "×”×¤×•×¡×˜ ×™×©×Ÿ ××“×™"
            except:
                pass  # ×× ×™×© ×©×’×™××” ×‘×¤×¨×¡×•×¨ ×”×ª××¨×™×š, × ××©×™×š
        
        # ×‘×“×™×§×ª ×¦×™×•×Ÿ ××•×¢××“
        if post_data.get('candidate_score', 0) < 5.0:
            return False, "×¦×™×•×Ÿ ××•×¢××“ × ××•×š ××“×™"
        
        # ×‘×“×™×§×” ×× ×™×© ×”×ª×××” ×œ××©×¨×”
        if not post_data.get('matched_job'):
            return False, "××™×Ÿ ×”×ª×××” ×œ××©×¨×”"
        
        return True, "××ª××™× ×œ××¢× ×”"
    
    def analyze_post(self, post_text: str, author_name: str = "", 
                    posted_at: str = None) -> Dict:
        """
        × ×™×ª×•×— ××§×™×£ ×©×œ ×¤×•×¡×˜
        
        Returns:
            dict: ×›×œ ×”××™×“×¢ ×”×× ×•×ª×— ×¢×œ ×”×¤×•×¡×˜
        """
        # ×‘×“×™×§×” ×× ×–×” ××•×¢××“
        is_candidate, candidate_score, matched_keywords = self.is_candidate_post(post_text)
        
        result = {
            "is_candidate": is_candidate,
            "candidate_score": candidate_score,
            "matched_keywords": matched_keywords,
            "candidate_info": None,
            "matched_job": None,
            "should_respond": False,
            "reason": ""
        }
        
        if not is_candidate:
            result['reason'] = "×œ× ×–×•×”×” ×›××•×¢××“"
            return result
        
        # ×—×™×œ×•×¥ ××™×“×¢ ×¢×œ ×”××•×¢××“
        result['candidate_info'] = self.extract_candidate_info(post_text, author_name)
        
        # ×”×ª×××” ×œ××©×¨×”
        job_match = self.match_to_job(post_text, author_name)
        if job_match:
            result['matched_job'] = job_match
        
        # ×”×—×œ×˜×” ×× ×œ×¢× ×•×ª
        post_data = {
            'candidate_score': candidate_score,
            'matched_job': job_match,
            'posted_at': posted_at
        }
        should_respond, reason = self.should_respond(post_data)
        result['should_respond'] = should_respond
        result['reason'] = reason
        
        return result


# ×¤×•× ×§×¦×™×•×ª ×¢×–×¨
def get_matcher() -> CandidateMatcher:
    """×§×‘×œ×ª instance ×©×œ ×× ×•×¢ ×”×”×ª×××”"""
    return CandidateMatcher()


if __name__ == "__main__":
    # ×‘×“×™×§×” ×©×œ ×”×× ×•×¢
    matcher = CandidateMatcher()
    
    # ×“×•×’×××•×ª ×œ×‘×“×™×§×”
    test_posts = [
        {
            "text": "×”×™×™, ×× ×™ ××—×¤×© ×¢×‘×•×“×” ×‘××–×•×¨ ×¤×ª×— ×ª×§×•×•×”. ×™×© ×œ×™ × ×™×¡×™×•×Ÿ ×‘××›×™×¨×•×ª ×•×©×™×¨×•×ª ×œ×§×•×—×•×ª.",
            "author": "×“× ×™ ×›×”×Ÿ"
        },
        {
            "text": "×“×¨×•×©×™× ××™×™×“×™! ×—×‘×¨×ª× ×• ××—×¤×©×ª ×¢×•×‘×“×™× ×œ××›×™×¨×•×ª",
            "author": "×—×‘×¨×ª XYZ"
        },
        {
            "text": "××¢×•× ×™×™× ×ª ×‘××©×¨×” ×‘×ª×—×•× ×”×©×™×¨×•×ª, ×× ×™ ×’×¨×” ×‘×”×•×“ ×”×©×¨×•×Ÿ",
            "author": "××™×›×œ ×œ×•×™"
        }
    ]
    
    print("ğŸ” ×‘×“×™×§×ª ×× ×•×¢ ×”×”×ª×××”:\n")
    for i, post in enumerate(test_posts, 1):
        print(f"--- ×¤×•×¡×˜ #{i} ---")
        print(f"×˜×§×¡×˜: {post['text']}")
        print(f"××—×‘×¨: {post['author']}")
        
        analysis = matcher.analyze_post(post['text'], post['author'])
        
        print(f"×”×× ××•×¢××“: {'âœ… ×›×Ÿ' if analysis['is_candidate'] else 'âŒ ×œ×'}")
        print(f"×¦×™×•×Ÿ: {analysis['candidate_score']:.1f}/10")
        
        if analysis['matched_job']:
            print(f"××©×¨×” ××ª××™××”: {analysis['matched_job']['job_info']['title']}")
            print(f"×¦×™×•×Ÿ ×”×ª×××”: {analysis['matched_job']['match_score']:.1f}")
        
        print(f"×œ×¢× ×•×ª: {'âœ… ×›×Ÿ' if analysis['should_respond'] else 'âŒ ×œ×'}")
        print(f"×¡×™×‘×”: {analysis['reason']}\n")
